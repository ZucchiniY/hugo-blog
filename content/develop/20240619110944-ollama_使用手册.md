---
title: "ollama 使用手册"
author: ["夏南瓜"]
date: 2024-07-01T00:00:00+08:00
lastmod: 2024-07-01T16:33:49+08:00
series: ["ollama"]
tags: ["ollama", "docker", "tarfile"]
categories: ["开发"]
draft: false
---

Ollama 使用方式类似于 Docker 的使用方式，模型上传到 ollama 的镜像库中，使用的时候，可以直接用 `pull` 命令拉取。


## 安装方案 {#安装方案}

因为使用 Linux 和 MacOS 两套系统管理，两块的使用方案不同。

```shell
# darwin
brew install ollama
# linux
curl -fsSL https://ollama.com/install.sh | sh
```


## 拉取镜像 {#拉取镜像}

在安装 ollama 之后，可以直接运行 `ollama serve` 命令进行启动，然后用 `ollama pull llama3` 下载对应的 model 的镜像。

llava
: 写作模型，用来执行编写报告、文档相关的任务

llama3
: 比较好的英文处理模型，一些涉及英文理解的任务由此模型承担

qwen2
: 中文模型，使用中文编写脚本和任务清单的内容，由此模型担任


### 模型存储位置 {#模型存储位置}

MacOS
: ~/.ollama/models

linux
: _usr/share/ollama_.ollama/models

但是需要对模型进行共享，所以可以使用 `OLLAMA_MODELS` 来配置成相同的路径。

可以配置配置文件：

```js
#vi /etc/systemd/system/ollama.service
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin"
#配置远程访问
Environment="OLLAMA_HOST=0.0.0.0"
#配置跨域请求
Environment="OLLAMA_ORIGINS=*"
#配置OLLAMA的模型存放路径，防止内存不足，一般的默认路径是/usr/share/ollama/.ollama/models/
Environment="OLLAMA_MODELS=/home/ollama/.ollama/models"

[Install]
WantedBy=default.target
```

更新文件内容后，执行下面的命令：

```shell
##修改完后执行
sudo systemctl daemon-reload
sudo systemctl enable ollama
```


### 模型打包脚本 {#模型打包脚本}

在使用过程中，需要将 ollama 下载的模型分导入到其它环境中，但是随着模型的增加，其记录的信息也特别复杂，希望可以仅将某个模型打包而不是对整个 models/ 文件夹打包。

研究了一下 `ollama list` 命令下的数据，发现在 models 下面，blobs 中存储的是模型，而在 manifests 中存储的是对应的模型信息。

less 查看一下内容，发现是一段 json 代码，其中模型的数据主要是存储在 digest 对应的信息中。使用如下命令对模型进行打包；

```python
from pandas import json_normalize
import json
import pandas as pd
import os
import tarfile

json_path = '<ollama_models>/manifests/registry.ollama.ai/library/<model_name>/<model_version>'
blob_path = '<ollama_models>/blobs/'
tar_path = '<tar_path>'

with open(json_path) as f:
    df = json.load(f)

out = pd.json_normalize(df, record_path=['layers'], meta=['schemaVersion','mediaType','config'], meta_prefix='layer_')
results = list(map(lambda x: x.replace(':', '-'), out.digest.values))

files = list(map(lambda x: os.path.join(blob_path, x), results))

print(files)

outFileTarName = os.path.join(tar_path, "<model_name_version>.tar.gz")
with tarfile.open(outFileTarName, "w:gz") as tar:
    for file in files:
        tar.add(file)


print(outFileTarName)
```

之后如果使用 Fat32 U 盘备份的话，需要将 tar 文件切成多个文件，使用下命令：

```shell
split -b 500M -d -a 2 <tar_name>.tar.gz <tar_name>.tar.gz.
```

这里是按 500M 进行分包，每个包按 2 位数字进行命名。
